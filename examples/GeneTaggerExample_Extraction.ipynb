{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging genes with ddlite: candidate extraction\n",
    "\n",
    "## Introduction\n",
    "In this example **ddlite** app, we'll build a gene tagger from scratch. Domain-specific tagging systems take months or years to develop. They use hand-crafted model circuitry and accurate, hand-labeled training data. We'll start to build a pretty good one in a few minutes with none of those things. The generalized extraction and learning utilities provided by ddlite will allow us to turn a sampling of article abstracts and some basic domain knowledge into an automated tagging system. Specifically, we want an accurate tagger for genes in academic articles. We have comprehensive dictionaries of genes, but applying a simple matching rule might yield a lot of false positives. For example, \"p53\" might get tagged as a gene if it refers to a page number. Our goal is to use distant supervision to improve precision.\n",
    "\n",
    "Here's the pipeline we'll follow:\n",
    "\n",
    "1. Obtain and parse input data (relevant article abstracts from PubMed)\n",
    "2. Extract candidates for tagging\n",
    "3. Generate features\n",
    "4. Create a test set\n",
    "5. Write labeling functions\n",
    "6. Learn the tagging model\n",
    "7. Iterate on labeling functions\n",
    "\n",
    "Parts 1 and 2 are covered in this notebook, and parts 3 through 7 are covered in `GeneTaggerExample_Learning.ipynb`. Let's get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cPickle, os, sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input data\n",
    "We already downloaded the raw HTML for 150 gene-related article pages from PubMed using the `pubmed_gene_html.py` script. These can be found in the `data` folder. We can use ddlite's `DocParser` to read in the article text. There's a general HTML parser which finds visible text, but we can do better by writing a more specific version to just grab the abstract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('7802348.html', 'Thrombin is a serine protease able to evoke biological responses from a variety of cells, including platelets, endothelial cells, fibroblasts and smooth muscle cells. The structure of the thrombin receptor present in the human megakaryoblastic cell line and in hamster fibroblasts has recently been deduced by expression in the Xenopus laevis oocyte. The cloned receptor is a new member of the seven transmembrane domain receptor family that interacts with G proteins. A large amino-terminal extracellular extension has a cleavage site for thrombin (Leu Asp Pro Arg/Ser Phe Leu Leu,/representing the cleavage site). Thrombin cleaves at this site, unmasking a new amino terminus, that functions like a ligand, binding to an as yet undefined site and eliciting receptor activation. Peptides similar to a new amino terminus created after cleavage are able to mimic thrombin cellular effects. These agonist peptides are used to analyse the role of the cloned receptor in the thrombin-specific response.')\n"
     ]
    }
   ],
   "source": [
    "class PubMedAbstractReader(HTMLReader):\n",
    "    def _cleaner(self, s):\n",
    "        return (s.parent.name == 'abstracttext')\n",
    "\n",
    "dp = DocParser('gene_tag_example/data/', PubMedAbstractReader())\n",
    "docs = list(dp.readDocs())\n",
    "print docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use CoreNLP via ddlite's `SentenceParser` to parse each sentence. `DocParser` can handle this too; we didn't really need that call above. This can take a little while, so if the example has already been run, we'll reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.35 s, sys: 56 ms, total: 8.4 s\n",
      "Wall time: 53.5 s\n",
      "Sentence(words=[u'Thrombin', u'is', u'a', u'serine', u'protease', u'able', u'to', u'evoke', u'biological', u'responses', u'from', u'a', u'variety', u'of', u'cells', u',', u'including', u'platelets', u',', u'endothelial', u'cells', u',', u'fibroblasts', u'and', u'smooth', u'muscle', u'cells', u'.'], lemmas=[u'thrombin', u'be', u'a', u'serine', u'protease', u'able', u'to', u'evoke', u'biological', u'response', u'from', u'a', u'variety', u'of', u'cell', u',', u'include', u'platelet', u',', u'endothelial', u'cell', u',', u'fibroblast', u'and', u'smooth', u'muscle', u'cell', u'.'], poses=[u'NN', u'VBZ', u'DT', u'NN', u'NN', u'JJ', u'TO', u'VB', u'JJ', u'NNS', u'IN', u'DT', u'NN', u'IN', u'NNS', u',', u'VBG', u'NNS', u',', u'JJ', u'NNS', u',', u'NNS', u'CC', u'VB', u'NN', u'NNS', u'.'], dep_parents=[5, 5, 5, 5, 0, 5, 8, 6, 10, 8, 13, 13, 10, 15, 13, 15, 18, 15, 18, 21, 18, 18, 18, 18, 27, 27, 18, 5], dep_labels=[u'nsubj', u'cop', u'det', u'compound', u'ROOT', u'amod', u'mark', u'xcomp', u'amod', u'dobj', u'case', u'det', u'nmod', u'case', u'nmod', u'punct', u'case', u'nmod', u'punct', u'amod', u'conj', u'punct', u'conj', u'cc', u'amod', u'compound', u'conj', u'punct'], sent_id=0, doc_id='7802348.html', text=u'Thrombin is a serine protease able to evoke biological responses from a variety of cells, including platelets, endothelial cells, fibroblasts and smooth muscle cells.', token_idxs=[0, 9, 12, 14, 21, 30, 35, 38, 44, 55, 65, 70, 72, 80, 83, 88, 90, 100, 109, 111, 123, 128, 130, 142, 146, 153, 160, 165], doc_name='7802348.html')\n"
     ]
    }
   ],
   "source": [
    "docs = None\n",
    "\n",
    "pkl_f = 'gene_tag_example/gene_tag_saved_sents_v5.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        sents = cPickle.load(f)\n",
    "except:\n",
    "    %time sents = dp.parseDocSentences()\n",
    "    with open(pkl_f, 'w+') as f:\n",
    "        cPickle.dump(sents, f)\n",
    "\n",
    "print sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting candidates with matchers\n",
    "Extracting candidates for mentions (or relations) in ddlite is done with `Matcher` objects. First, we'll use a `DictionaryMatcher`. We have access to a pretty comprehensive gene dictionary. Let's load it in and create the `DictionaryMatcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('gene_tag_example/dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 2, genes)\n",
    "\n",
    "gene_dm = DictionaryMatch(label='GeneName', dictionary=genes, ignore_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary match should provide fairly high recall, but we may still miss some candidates. We know that gene names are named nouns and are often all uppercase. Let's use DDLite's *compositional* matcher operations to handle this. First, we'll write a matcher to find all nouns using the parts-of-speech tags. Then, we'll use a filter to find uppercase sequences. Finally, we'll use a filter to make sure each match has at least 3 characters. We pass `noun_rm` to `up_rm`, and `up_rm` to the final filter to compose them with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noun_regex = RegexNgramMatch(label='Nouns', regex_pattern=r'[A-Z]?NN[A-Z]?', ignore_case=True, match_attrib='poses')\n",
    "up_regex = RegexFilterAll(noun_regex, label='Upper', regex_pattern=r'[A-Z]+([0-9]+)?([A-Z]+)?([0-9]+)?$', ignore_case=False, match_attrib='words')\n",
    "multi_regex = RegexFilterAll(up_regex, label='Multi', regex_pattern=r'[a-z0-9]{3,}', ignore_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want matches both from the dictionary and the uppercase-noun-phrase-matcher we just built, we'll use the union object to create a matcher for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CE = Union(gene_dm, multi_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the candidates\n",
    "We'll use our unioned candidate extractor to extract our candidate entities from the sentences into an `Entities` object. Using both matchers together will provide very high recall, but may have poor precision. In the next demo notebook (`GeneTaggerExample_Learning.ipynb`), we'll write distant supervision rules and learn a model to improve precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E = Entities(sents, CE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize contexts for our extractions too. This may help in writing labeling functions in `GeneTaggerExample_Learning.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-3187829171225614358\"></div>\n",
       "<div id=\"raw-seq-3187829171225614358\">\n",
       "<span class=\"word-3187829171225614358-0\">Blood</span> <span class=\"word-3187829171225614358-1\">levels</span> <span class=\"word-3187829171225614358-2\">of</span> <span class=\"word-3187829171225614358-3\">adiponectin</span> <span class=\"word-3187829171225614358-4\">,</span> <span class=\"word-3187829171225614358-5\">an</span> <span class=\"word-3187829171225614358-6\">adipocyte-secreted</span> <span class=\"word-3187829171225614358-7\">protein</span> <span class=\"word-3187829171225614358-8\">correlated</span> <span class=\"word-3187829171225614358-9\">with</span> <span class=\"word-3187829171225614358-10\">metabolic</span> <span class=\"word-3187829171225614358-11\">and</span> <span class=\"word-3187829171225614358-12\">cardiovascular</span> <span class=\"word-3187829171225614358-13\">risks</span> <span class=\"word-3187829171225614358-14\">,</span> <span class=\"word-3187829171225614358-15\">are</span> <span class=\"word-3187829171225614358-16\">highly</span> <span class=\"word-3187829171225614358-17\">heritable</span> <span class=\"word-3187829171225614358-18\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"3187829171225614358\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"122\", \"word\": \"heritable\", \"dep_label\": \"ROOT\", \"pos\": \"JJ\", \"lemma\": \"heritable\", \"word_idx\": \"17\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"59\", \"word\": \"correlated\", \"dep_label\": \"dep\", \"pos\": \"VBD\", \"lemma\": \"correlate\", \"word_idx\": \"8\", \"dep_parent\": \"18\"}, \"children\": [{\"attrib\": {\"token_idx\": \"6\", \"word\": \"levels\", \"dep_label\": \"nsubj\", \"pos\": \"NNS\", \"lemma\": \"level\", \"word_idx\": \"1\", \"dep_parent\": \"9\"}, \"children\": [{\"attrib\": {\"token_idx\": \"0\", \"word\": \"Blood\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"blood\", \"word_idx\": \"0\", \"dep_parent\": \"2\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"16\", \"word\": \"adiponectin\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"adiponectin\", \"word_idx\": \"3\", \"dep_parent\": \"2\"}, \"children\": [{\"attrib\": {\"token_idx\": \"13\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"2\", \"dep_parent\": \"4\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"27\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"4\", \"dep_parent\": \"4\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"51\", \"word\": \"protein\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"protein\", \"word_idx\": \"7\", \"dep_parent\": \"4\"}, \"children\": [{\"attrib\": {\"token_idx\": \"29\", \"word\": \"an\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"5\", \"dep_parent\": \"8\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"32\", \"word\": \"adipocyte-secreted\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"adipocyte-secreted\", \"word_idx\": \"6\", \"dep_parent\": \"8\"}, \"children\": []}]}]}]}, {\"attrib\": {\"token_idx\": \"104\", \"word\": \"risks\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"risk\", \"word_idx\": \"13\", \"dep_parent\": \"9\"}, \"children\": [{\"attrib\": {\"token_idx\": \"70\", \"word\": \"with\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"with\", \"word_idx\": \"9\", \"dep_parent\": \"14\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"75\", \"word\": \"metabolic\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"metabolic\", \"word_idx\": \"10\", \"dep_parent\": \"14\"}, \"children\": [{\"attrib\": {\"token_idx\": \"85\", \"word\": \"and\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"and\", \"word_idx\": \"11\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"89\", \"word\": \"cardiovascular\", \"dep_label\": \"conj\", \"pos\": \"JJ\", \"lemma\": \"cardiovascular\", \"word_idx\": \"12\", \"dep_parent\": \"11\"}, \"children\": []}]}]}, {\"attrib\": {\"token_idx\": \"109\", \"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"14\", \"dep_parent\": \"9\"}, \"children\": []}]}, {\"attrib\": {\"token_idx\": \"111\", \"word\": \"are\", \"dep_label\": \"cop\", \"pos\": \"VBP\", \"lemma\": \"be\", \"word_idx\": \"15\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"115\", \"word\": \"highly\", \"dep_label\": \"advmod\", \"pos\": \"RB\", \"lemma\": \"highly\", \"word_idx\": \"16\", \"dep_parent\": \"18\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"131\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"18\", \"dep_parent\": \"18\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[3]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll pickle the extracted candidates from our `Entities` object for use in `GeneTaggerExample_Learning.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E.dump_candidates('gene_tag_example/gene_tag_saved_entities_v6.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
